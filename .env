# Higher temperature means the LLM will be more creative.
TEMPERATURE=0.9

# These configs are for the LLM to generate the next subdialogs.
MAX_NUM_TURNS_PER_SUBDIALOG=10
MIN_NUM_TURNS_PER_SUBDIALOG=1
SHORT_TURN_RATIO=0.2
SHORT_TURN_STANDARD_NUM_WORDS=2
MAX_NUM_WORDS_PER_TURN=250
MAX_NUM_TURNS_PER_LLM_CHUNCK=10
MAX_NUM_WORDS_IN_PROMPT=5120

# Send request to the LLM to prefab `N` next subdialogs while annotators are annotating to save time.
# Usually N = 1 is enough.
PREFAB_N=1

DISABLE_TQDM=False
LLM_VERSION="gpt-3.5-turbo-0301"

# Avoid sending too many requests to OpenAI API at the same time.
MAX_NUM_OPENAI_API_RETRY=5
API_COOLDOWN=5
MAX_NUM_SUBDIALOG_RETRY=3

# This is for creating the data for state-change models.
MOST_RECENT_K_TURNS_FOR_STATE_CHANGE=18